---
title: "Model reduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Model reduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(lgpr2)
```

## Model

```{r}
mod <- LonModel$new(y ~ gp(x1) + gp(x2) + gp(x3) + gp(x4))
```

## Experiment

Here we generate data with variables $x_1$, $x_2$, $x_3$ and $x_4$. Only
$x_2$ is associated with the response $y$ and others are irrelevant.

```{r}
run_experiment <- function(model, sigma = 0.2) {
  dat <- simulate(40, 0.3, c(0, 1, 0, 0), sigma)
  df <- data.frame(cbind(dat$x, dat$y))
  colnames(df)[ncol(df)] <- "y"
  model$fit(data = df, chains = 2, refresh = 0)
}
```

We first fit a full model with all variables included.

```{r}
fit <- run_experiment(mod)
```

## Relevances

Here we show how to rank components based on their relevance based on a 
variance decomposition.

```{r}
rank <- fit$rank_terms()
print(rank)
fit$reduce()
```

## Projection predictive method

Here we pre-specify the search path completely based on relevances.

```{r, fig.width=7, fig.height=4}
path_rel <- rank$order
print(path_rel)
fs <- pp_forward_search(fit, path_rel, 4)

plot_pp_pexp(fs)
plot_pp_elpd(fs, fit$loo_estimate())
```


Here we define only two steps of the path.

```{r, fig.width=7, fig.height=4}
fs2 <- pp_forward_search(fit, path = c(2, 3), 4)

plot_pp_pexp(fs2)
plot_pp_elpd(fs2, fit$loo_estimate())
```

